{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 10,
  "global_step": 591,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.050761421319796954,
      "grad_norm": 30.966703414916992,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 4.9699,
      "step": 10
    },
    {
      "epoch": 0.050761421319796954,
      "eval_loss": 4.2132954597473145,
      "eval_runtime": 29.3998,
      "eval_samples_per_second": 1.497,
      "eval_steps_per_second": 0.748,
      "step": 10
    },
    {
      "epoch": 0.10152284263959391,
      "grad_norm": 14.857179641723633,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 4.8252,
      "step": 20
    },
    {
      "epoch": 0.10152284263959391,
      "eval_loss": 4.076850414276123,
      "eval_runtime": 30.0961,
      "eval_samples_per_second": 1.462,
      "eval_steps_per_second": 0.731,
      "step": 20
    },
    {
      "epoch": 0.15228426395939088,
      "grad_norm": 14.077605247497559,
      "learning_rate": 3e-06,
      "loss": 4.6046,
      "step": 30
    },
    {
      "epoch": 0.15228426395939088,
      "eval_loss": 3.900312900543213,
      "eval_runtime": 37.2505,
      "eval_samples_per_second": 1.181,
      "eval_steps_per_second": 0.591,
      "step": 30
    },
    {
      "epoch": 0.20304568527918782,
      "grad_norm": 13.649974822998047,
      "learning_rate": 4.000000000000001e-06,
      "loss": 4.1471,
      "step": 40
    },
    {
      "epoch": 0.20304568527918782,
      "eval_loss": 3.662198781967163,
      "eval_runtime": 34.9805,
      "eval_samples_per_second": 1.258,
      "eval_steps_per_second": 0.629,
      "step": 40
    },
    {
      "epoch": 0.25380710659898476,
      "grad_norm": 11.377331733703613,
      "learning_rate": 5e-06,
      "loss": 3.8556,
      "step": 50
    },
    {
      "epoch": 0.25380710659898476,
      "eval_loss": 3.317432165145874,
      "eval_runtime": 35.1082,
      "eval_samples_per_second": 1.253,
      "eval_steps_per_second": 0.627,
      "step": 50
    },
    {
      "epoch": 0.30456852791878175,
      "grad_norm": 9.273543357849121,
      "learning_rate": 6e-06,
      "loss": 3.4283,
      "step": 60
    },
    {
      "epoch": 0.30456852791878175,
      "eval_loss": 3.028886556625366,
      "eval_runtime": 32.4029,
      "eval_samples_per_second": 1.358,
      "eval_steps_per_second": 0.679,
      "step": 60
    },
    {
      "epoch": 0.3553299492385787,
      "grad_norm": 8.496755599975586,
      "learning_rate": 7.000000000000001e-06,
      "loss": 3.2189,
      "step": 70
    },
    {
      "epoch": 0.3553299492385787,
      "eval_loss": 2.738224983215332,
      "eval_runtime": 34.8336,
      "eval_samples_per_second": 1.263,
      "eval_steps_per_second": 0.632,
      "step": 70
    },
    {
      "epoch": 0.40609137055837563,
      "grad_norm": 7.37190580368042,
      "learning_rate": 8.000000000000001e-06,
      "loss": 2.8279,
      "step": 80
    },
    {
      "epoch": 0.40609137055837563,
      "eval_loss": 2.5315096378326416,
      "eval_runtime": 32.763,
      "eval_samples_per_second": 1.343,
      "eval_steps_per_second": 0.671,
      "step": 80
    },
    {
      "epoch": 0.45685279187817257,
      "grad_norm": 6.901695251464844,
      "learning_rate": 9e-06,
      "loss": 2.639,
      "step": 90
    },
    {
      "epoch": 0.45685279187817257,
      "eval_loss": 2.3466639518737793,
      "eval_runtime": 31.8982,
      "eval_samples_per_second": 1.379,
      "eval_steps_per_second": 0.69,
      "step": 90
    },
    {
      "epoch": 0.5076142131979695,
      "grad_norm": 7.938910007476807,
      "learning_rate": 1e-05,
      "loss": 2.6392,
      "step": 100
    },
    {
      "epoch": 0.5076142131979695,
      "eval_loss": 2.1952569484710693,
      "eval_runtime": 31.806,
      "eval_samples_per_second": 1.383,
      "eval_steps_per_second": 0.692,
      "step": 100
    },
    {
      "epoch": 0.5583756345177665,
      "grad_norm": 11.806139945983887,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 2.3898,
      "step": 110
    },
    {
      "epoch": 0.5583756345177665,
      "eval_loss": 2.0760610103607178,
      "eval_runtime": 31.6928,
      "eval_samples_per_second": 1.388,
      "eval_steps_per_second": 0.694,
      "step": 110
    },
    {
      "epoch": 0.6091370558375635,
      "grad_norm": 8.977227210998535,
      "learning_rate": 1.2e-05,
      "loss": 2.2601,
      "step": 120
    },
    {
      "epoch": 0.6091370558375635,
      "eval_loss": 1.9626556634902954,
      "eval_runtime": 31.7789,
      "eval_samples_per_second": 1.385,
      "eval_steps_per_second": 0.692,
      "step": 120
    },
    {
      "epoch": 0.6598984771573604,
      "grad_norm": 8.184053421020508,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 2.0972,
      "step": 130
    },
    {
      "epoch": 0.6598984771573604,
      "eval_loss": 1.8535517454147339,
      "eval_runtime": 32.7666,
      "eval_samples_per_second": 1.343,
      "eval_steps_per_second": 0.671,
      "step": 130
    },
    {
      "epoch": 0.7106598984771574,
      "grad_norm": 7.1303300857543945,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 1.9576,
      "step": 140
    },
    {
      "epoch": 0.7106598984771574,
      "eval_loss": 1.7629368305206299,
      "eval_runtime": 30.9657,
      "eval_samples_per_second": 1.421,
      "eval_steps_per_second": 0.71,
      "step": 140
    },
    {
      "epoch": 0.7614213197969543,
      "grad_norm": 10.007413864135742,
      "learning_rate": 1.5e-05,
      "loss": 1.8222,
      "step": 150
    },
    {
      "epoch": 0.7614213197969543,
      "eval_loss": 1.6866081953048706,
      "eval_runtime": 31.784,
      "eval_samples_per_second": 1.384,
      "eval_steps_per_second": 0.692,
      "step": 150
    },
    {
      "epoch": 0.8121827411167513,
      "grad_norm": 12.610899925231934,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 1.9855,
      "step": 160
    },
    {
      "epoch": 0.8121827411167513,
      "eval_loss": 1.6097537279129028,
      "eval_runtime": 33.0521,
      "eval_samples_per_second": 1.331,
      "eval_steps_per_second": 0.666,
      "step": 160
    },
    {
      "epoch": 0.8629441624365483,
      "grad_norm": 7.718392848968506,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 1.7515,
      "step": 170
    },
    {
      "epoch": 0.8629441624365483,
      "eval_loss": 1.5396647453308105,
      "eval_runtime": 33.8574,
      "eval_samples_per_second": 1.3,
      "eval_steps_per_second": 0.65,
      "step": 170
    },
    {
      "epoch": 0.9137055837563451,
      "grad_norm": 14.932454109191895,
      "learning_rate": 1.8e-05,
      "loss": 1.8306,
      "step": 180
    },
    {
      "epoch": 0.9137055837563451,
      "eval_loss": 1.4818336963653564,
      "eval_runtime": 33.037,
      "eval_samples_per_second": 1.332,
      "eval_steps_per_second": 0.666,
      "step": 180
    },
    {
      "epoch": 0.9644670050761421,
      "grad_norm": 12.523064613342285,
      "learning_rate": 1.9e-05,
      "loss": 1.4974,
      "step": 190
    },
    {
      "epoch": 0.9644670050761421,
      "eval_loss": 1.4380919933319092,
      "eval_runtime": 31.5057,
      "eval_samples_per_second": 1.397,
      "eval_steps_per_second": 0.698,
      "step": 190
    },
    {
      "epoch": 1.015228426395939,
      "grad_norm": 8.553607940673828,
      "learning_rate": 2e-05,
      "loss": 1.6846,
      "step": 200
    },
    {
      "epoch": 1.015228426395939,
      "eval_loss": 1.4026708602905273,
      "eval_runtime": 31.8971,
      "eval_samples_per_second": 1.379,
      "eval_steps_per_second": 0.69,
      "step": 200
    },
    {
      "epoch": 1.0659898477157361,
      "grad_norm": 12.443800926208496,
      "learning_rate": 2.1e-05,
      "loss": 1.6574,
      "step": 210
    },
    {
      "epoch": 1.0659898477157361,
      "eval_loss": 1.3765207529067993,
      "eval_runtime": 29.4179,
      "eval_samples_per_second": 1.496,
      "eval_steps_per_second": 0.748,
      "step": 210
    },
    {
      "epoch": 1.116751269035533,
      "grad_norm": 9.425243377685547,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 1.6133,
      "step": 220
    },
    {
      "epoch": 1.116751269035533,
      "eval_loss": 1.3406742811203003,
      "eval_runtime": 29.3532,
      "eval_samples_per_second": 1.499,
      "eval_steps_per_second": 0.749,
      "step": 220
    },
    {
      "epoch": 1.16751269035533,
      "grad_norm": 6.62037992477417,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 1.4344,
      "step": 230
    },
    {
      "epoch": 1.16751269035533,
      "eval_loss": 1.3327058553695679,
      "eval_runtime": 29.2739,
      "eval_samples_per_second": 1.503,
      "eval_steps_per_second": 0.752,
      "step": 230
    },
    {
      "epoch": 1.218274111675127,
      "grad_norm": 4.541355133056641,
      "learning_rate": 2.4e-05,
      "loss": 1.4007,
      "step": 240
    },
    {
      "epoch": 1.218274111675127,
      "eval_loss": 1.313994288444519,
      "eval_runtime": 28.9873,
      "eval_samples_per_second": 1.518,
      "eval_steps_per_second": 0.759,
      "step": 240
    },
    {
      "epoch": 1.2690355329949239,
      "grad_norm": 6.688156604766846,
      "learning_rate": 2.5e-05,
      "loss": 1.4762,
      "step": 250
    },
    {
      "epoch": 1.2690355329949239,
      "eval_loss": 1.304343819618225,
      "eval_runtime": 29.1127,
      "eval_samples_per_second": 1.511,
      "eval_steps_per_second": 0.756,
      "step": 250
    },
    {
      "epoch": 1.3197969543147208,
      "grad_norm": 5.723019123077393,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 1.3104,
      "step": 260
    },
    {
      "epoch": 1.3197969543147208,
      "eval_loss": 1.2760658264160156,
      "eval_runtime": 29.4407,
      "eval_samples_per_second": 1.495,
      "eval_steps_per_second": 0.747,
      "step": 260
    },
    {
      "epoch": 1.3705583756345177,
      "grad_norm": 6.548392295837402,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 1.1048,
      "step": 270
    },
    {
      "epoch": 1.3705583756345177,
      "eval_loss": 1.254521131515503,
      "eval_runtime": 29.2263,
      "eval_samples_per_second": 1.505,
      "eval_steps_per_second": 0.753,
      "step": 270
    },
    {
      "epoch": 1.4213197969543148,
      "grad_norm": 5.043571949005127,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 1.484,
      "step": 280
    },
    {
      "epoch": 1.4213197969543148,
      "eval_loss": 1.2518596649169922,
      "eval_runtime": 29.1883,
      "eval_samples_per_second": 1.507,
      "eval_steps_per_second": 0.754,
      "step": 280
    },
    {
      "epoch": 1.4720812182741116,
      "grad_norm": 8.445704460144043,
      "learning_rate": 2.9e-05,
      "loss": 1.1455,
      "step": 290
    },
    {
      "epoch": 1.4720812182741116,
      "eval_loss": 1.2365226745605469,
      "eval_runtime": 29.55,
      "eval_samples_per_second": 1.489,
      "eval_steps_per_second": 0.745,
      "step": 290
    },
    {
      "epoch": 1.5228426395939088,
      "grad_norm": 6.766172885894775,
      "learning_rate": 3e-05,
      "loss": 1.1675,
      "step": 300
    },
    {
      "epoch": 1.5228426395939088,
      "eval_loss": 1.2215361595153809,
      "eval_runtime": 31.8068,
      "eval_samples_per_second": 1.383,
      "eval_steps_per_second": 0.692,
      "step": 300
    },
    {
      "epoch": 1.5736040609137056,
      "grad_norm": 5.030069351196289,
      "learning_rate": 3.1e-05,
      "loss": 1.2101,
      "step": 310
    },
    {
      "epoch": 1.5736040609137056,
      "eval_loss": 1.2122708559036255,
      "eval_runtime": 29.2292,
      "eval_samples_per_second": 1.505,
      "eval_steps_per_second": 0.753,
      "step": 310
    },
    {
      "epoch": 1.6243654822335025,
      "grad_norm": 4.910078525543213,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 1.2431,
      "step": 320
    },
    {
      "epoch": 1.6243654822335025,
      "eval_loss": 1.2149604558944702,
      "eval_runtime": 31.6011,
      "eval_samples_per_second": 1.392,
      "eval_steps_per_second": 0.696,
      "step": 320
    },
    {
      "epoch": 1.6751269035532994,
      "grad_norm": 8.086282730102539,
      "learning_rate": 3.3e-05,
      "loss": 1.1588,
      "step": 330
    },
    {
      "epoch": 1.6751269035532994,
      "eval_loss": 1.1996303796768188,
      "eval_runtime": 35.071,
      "eval_samples_per_second": 1.255,
      "eval_steps_per_second": 0.627,
      "step": 330
    },
    {
      "epoch": 1.7258883248730963,
      "grad_norm": 4.994334697723389,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 1.2008,
      "step": 340
    },
    {
      "epoch": 1.7258883248730963,
      "eval_loss": 1.1953353881835938,
      "eval_runtime": 32.8596,
      "eval_samples_per_second": 1.339,
      "eval_steps_per_second": 0.67,
      "step": 340
    },
    {
      "epoch": 1.7766497461928934,
      "grad_norm": 7.364628791809082,
      "learning_rate": 3.5e-05,
      "loss": 1.265,
      "step": 350
    },
    {
      "epoch": 1.7766497461928934,
      "eval_loss": 1.1806330680847168,
      "eval_runtime": 28.9508,
      "eval_samples_per_second": 1.52,
      "eval_steps_per_second": 0.76,
      "step": 350
    },
    {
      "epoch": 1.8274111675126905,
      "grad_norm": 6.48333740234375,
      "learning_rate": 3.6e-05,
      "loss": 1.0934,
      "step": 360
    },
    {
      "epoch": 1.8274111675126905,
      "eval_loss": 1.1788538694381714,
      "eval_runtime": 29.0507,
      "eval_samples_per_second": 1.515,
      "eval_steps_per_second": 0.757,
      "step": 360
    },
    {
      "epoch": 1.8781725888324874,
      "grad_norm": 7.552213668823242,
      "learning_rate": 3.7e-05,
      "loss": 1.3797,
      "step": 370
    },
    {
      "epoch": 1.8781725888324874,
      "eval_loss": 1.1735936403274536,
      "eval_runtime": 29.4355,
      "eval_samples_per_second": 1.495,
      "eval_steps_per_second": 0.747,
      "step": 370
    },
    {
      "epoch": 1.9289340101522843,
      "grad_norm": 6.152806758880615,
      "learning_rate": 3.8e-05,
      "loss": 1.0762,
      "step": 380
    },
    {
      "epoch": 1.9289340101522843,
      "eval_loss": 1.1603676080703735,
      "eval_runtime": 29.4076,
      "eval_samples_per_second": 1.496,
      "eval_steps_per_second": 0.748,
      "step": 380
    },
    {
      "epoch": 1.9796954314720812,
      "grad_norm": 11.420744895935059,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 1.282,
      "step": 390
    },
    {
      "epoch": 1.9796954314720812,
      "eval_loss": 1.1564639806747437,
      "eval_runtime": 29.3958,
      "eval_samples_per_second": 1.497,
      "eval_steps_per_second": 0.748,
      "step": 390
    },
    {
      "epoch": 2.030456852791878,
      "grad_norm": 6.430358409881592,
      "learning_rate": 4e-05,
      "loss": 1.0989,
      "step": 400
    },
    {
      "epoch": 2.030456852791878,
      "eval_loss": 1.154097318649292,
      "eval_runtime": 29.1743,
      "eval_samples_per_second": 1.508,
      "eval_steps_per_second": 0.754,
      "step": 400
    },
    {
      "epoch": 2.081218274111675,
      "grad_norm": 6.321652412414551,
      "learning_rate": 4.1e-05,
      "loss": 1.101,
      "step": 410
    },
    {
      "epoch": 2.081218274111675,
      "eval_loss": 1.1480485200881958,
      "eval_runtime": 29.2479,
      "eval_samples_per_second": 1.504,
      "eval_steps_per_second": 0.752,
      "step": 410
    },
    {
      "epoch": 2.1319796954314723,
      "grad_norm": 5.721968173980713,
      "learning_rate": 4.2e-05,
      "loss": 1.1594,
      "step": 420
    },
    {
      "epoch": 2.1319796954314723,
      "eval_loss": 1.1592764854431152,
      "eval_runtime": 28.8516,
      "eval_samples_per_second": 1.525,
      "eval_steps_per_second": 0.763,
      "step": 420
    },
    {
      "epoch": 2.182741116751269,
      "grad_norm": 5.2383856773376465,
      "learning_rate": 4.3e-05,
      "loss": 0.9795,
      "step": 430
    },
    {
      "epoch": 2.182741116751269,
      "eval_loss": 1.141778826713562,
      "eval_runtime": 29.6549,
      "eval_samples_per_second": 1.484,
      "eval_steps_per_second": 0.742,
      "step": 430
    },
    {
      "epoch": 2.233502538071066,
      "grad_norm": 5.766260147094727,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 1.0088,
      "step": 440
    },
    {
      "epoch": 2.233502538071066,
      "eval_loss": 1.1457139253616333,
      "eval_runtime": 29.0587,
      "eval_samples_per_second": 1.514,
      "eval_steps_per_second": 0.757,
      "step": 440
    },
    {
      "epoch": 2.284263959390863,
      "grad_norm": 6.884564399719238,
      "learning_rate": 4.5e-05,
      "loss": 0.9999,
      "step": 450
    },
    {
      "epoch": 2.284263959390863,
      "eval_loss": 1.1371440887451172,
      "eval_runtime": 29.1564,
      "eval_samples_per_second": 1.509,
      "eval_steps_per_second": 0.755,
      "step": 450
    },
    {
      "epoch": 2.33502538071066,
      "grad_norm": 4.660024166107178,
      "learning_rate": 4.600000000000001e-05,
      "loss": 1.041,
      "step": 460
    },
    {
      "epoch": 2.33502538071066,
      "eval_loss": 1.1355899572372437,
      "eval_runtime": 29.6696,
      "eval_samples_per_second": 1.483,
      "eval_steps_per_second": 0.741,
      "step": 460
    },
    {
      "epoch": 2.3857868020304567,
      "grad_norm": 8.649693489074707,
      "learning_rate": 4.7e-05,
      "loss": 1.1928,
      "step": 470
    },
    {
      "epoch": 2.3857868020304567,
      "eval_loss": 1.1443477869033813,
      "eval_runtime": 28.9605,
      "eval_samples_per_second": 1.519,
      "eval_steps_per_second": 0.76,
      "step": 470
    },
    {
      "epoch": 2.436548223350254,
      "grad_norm": 4.943569660186768,
      "learning_rate": 4.8e-05,
      "loss": 1.0757,
      "step": 480
    },
    {
      "epoch": 2.436548223350254,
      "eval_loss": 1.1312355995178223,
      "eval_runtime": 28.8602,
      "eval_samples_per_second": 1.525,
      "eval_steps_per_second": 0.762,
      "step": 480
    },
    {
      "epoch": 2.487309644670051,
      "grad_norm": 6.466842174530029,
      "learning_rate": 4.9e-05,
      "loss": 1.1339,
      "step": 490
    },
    {
      "epoch": 2.487309644670051,
      "eval_loss": 1.1256303787231445,
      "eval_runtime": 29.5127,
      "eval_samples_per_second": 1.491,
      "eval_steps_per_second": 0.745,
      "step": 490
    },
    {
      "epoch": 2.5380710659898478,
      "grad_norm": 5.981884956359863,
      "learning_rate": 5e-05,
      "loss": 1.0285,
      "step": 500
    },
    {
      "epoch": 2.5380710659898478,
      "eval_loss": 1.1225203275680542,
      "eval_runtime": 30.3687,
      "eval_samples_per_second": 1.449,
      "eval_steps_per_second": 0.724,
      "step": 500
    },
    {
      "epoch": 2.5888324873096447,
      "grad_norm": 5.860714912414551,
      "learning_rate": 4.4505494505494504e-05,
      "loss": 1.077,
      "step": 510
    },
    {
      "epoch": 2.5888324873096447,
      "eval_loss": 1.1208128929138184,
      "eval_runtime": 28.8841,
      "eval_samples_per_second": 1.523,
      "eval_steps_per_second": 0.762,
      "step": 510
    },
    {
      "epoch": 2.6395939086294415,
      "grad_norm": 6.450997829437256,
      "learning_rate": 3.901098901098901e-05,
      "loss": 1.0029,
      "step": 520
    },
    {
      "epoch": 2.6395939086294415,
      "eval_loss": 1.1147303581237793,
      "eval_runtime": 29.1478,
      "eval_samples_per_second": 1.51,
      "eval_steps_per_second": 0.755,
      "step": 520
    },
    {
      "epoch": 2.6903553299492384,
      "grad_norm": 4.971694469451904,
      "learning_rate": 3.3516483516483513e-05,
      "loss": 0.9472,
      "step": 530
    },
    {
      "epoch": 2.6903553299492384,
      "eval_loss": 1.1109912395477295,
      "eval_runtime": 28.5871,
      "eval_samples_per_second": 1.539,
      "eval_steps_per_second": 0.77,
      "step": 530
    },
    {
      "epoch": 2.7411167512690353,
      "grad_norm": 4.803797245025635,
      "learning_rate": 2.8021978021978025e-05,
      "loss": 1.072,
      "step": 540
    },
    {
      "epoch": 2.7411167512690353,
      "eval_loss": 1.102827548980713,
      "eval_runtime": 28.7297,
      "eval_samples_per_second": 1.532,
      "eval_steps_per_second": 0.766,
      "step": 540
    },
    {
      "epoch": 2.7918781725888326,
      "grad_norm": 5.427087783813477,
      "learning_rate": 2.252747252747253e-05,
      "loss": 1.0198,
      "step": 550
    },
    {
      "epoch": 2.7918781725888326,
      "eval_loss": 1.1069703102111816,
      "eval_runtime": 29.4439,
      "eval_samples_per_second": 1.494,
      "eval_steps_per_second": 0.747,
      "step": 550
    },
    {
      "epoch": 2.8426395939086295,
      "grad_norm": 4.155777931213379,
      "learning_rate": 1.7032967032967035e-05,
      "loss": 1.0545,
      "step": 560
    },
    {
      "epoch": 2.8426395939086295,
      "eval_loss": 1.0993844270706177,
      "eval_runtime": 28.5846,
      "eval_samples_per_second": 1.539,
      "eval_steps_per_second": 0.77,
      "step": 560
    },
    {
      "epoch": 2.8934010152284264,
      "grad_norm": 5.650148868560791,
      "learning_rate": 1.153846153846154e-05,
      "loss": 1.1951,
      "step": 570
    },
    {
      "epoch": 2.8934010152284264,
      "eval_loss": 1.0960335731506348,
      "eval_runtime": 30.5516,
      "eval_samples_per_second": 1.44,
      "eval_steps_per_second": 0.72,
      "step": 570
    },
    {
      "epoch": 2.9441624365482233,
      "grad_norm": 4.580667972564697,
      "learning_rate": 6.043956043956044e-06,
      "loss": 0.9972,
      "step": 580
    },
    {
      "epoch": 2.9441624365482233,
      "eval_loss": 1.096256136894226,
      "eval_runtime": 29.8274,
      "eval_samples_per_second": 1.475,
      "eval_steps_per_second": 0.738,
      "step": 580
    },
    {
      "epoch": 2.99492385786802,
      "grad_norm": 6.631828308105469,
      "learning_rate": 5.494505494505495e-07,
      "loss": 0.908,
      "step": 590
    },
    {
      "epoch": 2.99492385786802,
      "eval_loss": 1.0958267450332642,
      "eval_runtime": 28.6908,
      "eval_samples_per_second": 1.534,
      "eval_steps_per_second": 0.767,
      "step": 590
    }
  ],
  "logging_steps": 10,
  "max_steps": 591,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 308063305728000.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
