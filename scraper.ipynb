{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 64365 five-digit numbers and saved to five_digit_numbers.txt.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Specify the input and output file names\n",
    "input_file = 'ebook_numbers.txt'  # Change this to your input file name\n",
    "output_file = 'five_digit_numbers.txt'\n",
    "\n",
    "# Read the content of the input file\n",
    "with open(input_file, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Use regular expression to find all 5-digit numbers\n",
    "five_digit_numbers = re.findall(r'\\b\\d{5}\\b', content)\n",
    "\n",
    "# Write the found numbers to the output file\n",
    "with open(output_file, 'w') as file:\n",
    "    for number in five_digit_numbers:\n",
    "        file.write(number + '\\n')\n",
    "\n",
    "print(f\"Found {len(five_digit_numbers)} five-digit numbers and saved to {output_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Specify the input file name containing the five-digit numbers\n",
    "input_file = 'five_digit_numbers.txt'  # Change this to your input file name\n",
    "\n",
    "# Read the content of the input file\n",
    "with open(input_file, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Use regular expression to find all 5-digit numbers\n",
    "five_digit_numbers = re.findall(r'\\b\\d{5}\\b', content)\n",
    "five_digit_numbers = five_digit_numbers[:500]  # Limit to the first 10 numbers\n",
    "# Initialize a list to store the extracted data\n",
    "all_data = []\n",
    "\n",
    "# Base URL for Project Gutenberg\n",
    "base_url = 'https://www.gutenberg.org/ebooks/'\n",
    "\n",
    "# Function to extract information from a given URL\n",
    "def extract_info(soup):\n",
    "    # Extract text\n",
    "    text = soup.get_text().replace('\\n', ' ').strip()\n",
    "\n",
    "    # Define a helper function to extract specific information\n",
    "    def extract_detail(start_keyword, end_keyword_1, end_keyword_2=None):\n",
    "        start_index = text.find(start_keyword)\n",
    "        if start_index != -1:\n",
    "            start_index += len(start_keyword)\n",
    "            end_index_1 = text.find(end_keyword_1, start_index)\n",
    "            end_index_2 = text.find(end_keyword_2, start_index) if end_keyword_2 else -1\n",
    "            \n",
    "            if end_index_1 == -1 and end_index_2 == -1:\n",
    "                return text[start_index:].strip().replace('\\n', ' ')\n",
    "            elif end_index_1 != -1 and (end_index_2 == -1 or end_index_1 < end_index_2):\n",
    "                return text[start_index:end_index_1].strip().replace('\\n', ' ')\n",
    "            elif end_index_2 != -1 and (end_index_1 == -1 or end_index_2 < end_index_1):\n",
    "                return text[start_index:end_index_2].strip().replace('\\n', ' ')\n",
    "        return None\n",
    "\n",
    "    # Extract relevant details\n",
    "    author = extract_detail(\"Author\", \"Title\")\n",
    "    title = extract_detail(\"Title\", \"Credits\")\n",
    "    credits = extract_detail(\"Credits\", \"Summary\")\n",
    "    summary = extract_detail(\"Summary\", \"Language\")\n",
    "    language = extract_detail(\"Language\", \"LoC Class\")\n",
    "    category = extract_detail(\"Category\", \"EBook-No\")\n",
    "    release_date = extract_detail(\"Release Date\", \"Most Recently Updated\", \"Copyright Status\")\n",
    "\n",
    "    # Extract subjects using \"Subject\" as delimiter\n",
    "    subjects_text = extract_detail(\"Subject\", \"Category\")\n",
    "    subjects = [subject.strip() for subject in subjects_text.split('Subject')[1:]] if subjects_text else []\n",
    "    subjects = subjects[:10]  # Limit to the first 10 subjects\n",
    "\n",
    "    # Extract the plain text link\n",
    "    plain_text_link = None\n",
    "    link_tag = soup.find(\"a\", string=lambda text: text and \"Plain Text\" in text)\n",
    "    if link_tag:\n",
    "        plain_text_link = \"https://www.gutenberg.org\" + link_tag['href']\n",
    "\n",
    "    # Create a dictionary for the current ebook\n",
    "    ebook_data = {\n",
    "        'Author': author,\n",
    "        'Title': title,\n",
    "        'Credits': credits,\n",
    "        'Summary': summary,\n",
    "        'Language': language,\n",
    "        'Category': category,\n",
    "        'Release Date': release_date,\n",
    "        'Plain Text Link': plain_text_link\n",
    "    }\n",
    "\n",
    "    # Add subjects to the dictionary, ensuring a maximum of 10\n",
    "    for i in range(1, 11):  # 1 to 10 for subjects\n",
    "        ebook_data[f'Subject{i}'] = subjects[i - 1] if i - 1 < len(subjects) else None\n",
    "\n",
    "    # Filter out unwanted text patterns\n",
    "    unwanted_patterns = [\n",
    "        \"Copyright Status\",\n",
    "        \"Downloads\",\n",
    "        \"Project Gutenberg\",\n",
    "        \"Privacy policy\",\n",
    "        \"Terms of Use\",\n",
    "        \"Contact Information\",\n",
    "        \"Get Help\"\n",
    "    ]\n",
    "\n",
    "    # Check for unwanted patterns in the data before adding to the list\n",
    "    if not any(pattern in str(ebook_data.values()) for pattern in unwanted_patterns):\n",
    "        return ebook_data\n",
    "    return None\n",
    "\n",
    "# Loop through each five-digit number to construct the URL and scrape data\n",
    "for number in five_digit_numbers:\n",
    "    url = f\"{base_url}{number}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        ebook_info = extract_info(soup)\n",
    "        if ebook_info:  # Only append if ebook_info is not None\n",
    "            all_data.append(ebook_info)\n",
    "    else:\n",
    "        print(f\"Failed to retrieve: {url}\")\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "# Step 6: Save to CSV\n",
    "df.to_csv('extracted_ebooks_info.csv', index=False, sep=',')\n",
    "print(\"Data saved successfully to 'extracted_ebooks_info.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Author  \\\n",
      "0                       Marryat, Florence, 1837-1899   \n",
      "1  Mead, Lucia True Ames, 1856-1936   LoC No.  07...   \n",
      "2      Wharton, Edith, 1862-1937   LoC No.  25008793   \n",
      "3                             Coppard, William Isaac   \n",
      "4  Nicholson, Meredith, 1866-1947   LoC No.  2101...   \n",
      "\n",
      "                                               Title  \\\n",
      "0  A moment of madness, and other stories (vol. 1...   \n",
      "1  Memoirs of a millionaire   Original Publicatio...   \n",
      "2  The mother's recompense   Original Publication...   \n",
      "3  Cottage scenes during the cholerabeing extract...   \n",
      "4  The man in the street: Papers on American topi...   \n",
      "\n",
      "                                             Credits  \\\n",
      "0  Emmanuel Ackerman and the Online Distributed P...   \n",
      "1  Richard Tonsing and the Online Distributed Pro...   \n",
      "2  Emmanuel Ackerman, David E. Brown, and the Onl...   \n",
      "3  Transcribed from the 1848 F. & J. Rivington ed...   \n",
      "4  D A Alexander, David E. Brown, and the Online ...   \n",
      "\n",
      "                                             Summary Language Category  \\\n",
      "0  \"A Moment of Madness\" by Florence Marryat is a...  English     Text   \n",
      "1  \"Memoirs of a Millionaire\" by Lucia True Ames ...  English     Text   \n",
      "2  \"The Mother's Recompense\" by Edith Wharton is ...  English     Text   \n",
      "3  \"Cottage Scenes During the Cholera\" by William...  English     Text   \n",
      "4  \"The Man in the Street: Papers on American Top...  English     Text   \n",
      "\n",
      "  Release Date                                   Plain Text Link  \\\n",
      "0  Jan 1, 2024  https://www.gutenberg.org/ebooks/72574.txt.utf-8   \n",
      "1  Jan 1, 2023  https://www.gutenberg.org/ebooks/69678.txt.utf-8   \n",
      "2  Jan 1, 2024  https://www.gutenberg.org/ebooks/72573.txt.utf-8   \n",
      "3  Jan 1, 2022  https://www.gutenberg.org/ebooks/67063.txt.utf-8   \n",
      "4  Jan 1, 2023  https://www.gutenberg.org/ebooks/69677.txt.utf-8   \n",
      "\n",
      "                            Subject1                          Subject2  \\\n",
      "0             Short stories, English                              None   \n",
      "1   Women philanthropists -- Fiction                              None   \n",
      "2              Psychological fiction  Mothers and daughters -- Fiction   \n",
      "3  Coppard, William Isaac -- Diaries                              None   \n",
      "4                               None                              None   \n",
      "\n",
      "                      Subject3 Subject4 Subject5 Subject6 Subject7 Subject8  \\\n",
      "0                         None     None     None     None     None     None   \n",
      "1                         None     None     None     None     None     None   \n",
      "2  Riviera (France) -- Fiction     None     None     None     None     None   \n",
      "3                         None     None     None     None     None     None   \n",
      "4                         None     None     None     None     None     None   \n",
      "\n",
      "  Subject9 Subject10  \n",
      "0     None      None  \n",
      "1     None      None  \n",
      "2     None      None  \n",
      "3     None      None  \n",
      "4     None      None  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "“is310”",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
